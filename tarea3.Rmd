---
title: "tarea3"
author: "Miguel Figueira"
date: "6 de abril de 2016"
output: html_document
---

- Leer archivos

```{r}

setwd("C:/Users/Alex/Documents/R/DM_T3/AprendizajeNoSupervisado/datos")


a <- read.csv(file = "a.csv",header= F)
a$V3 <- a$V3 +1 
table(a$V3)


ds.clust = function(ds,distan,metodo,nclass,altura,predecir){
  
  print(paste("el metodo es:",metodo,"usando distancia:",distan))
  # Encontramos modelo
  ds.matrix <- as.matrix(ds)
  
  distancia <- dist(x = ds.matrix , method = distan)
  
  cluster <- hclust(d = distancia,method = metodo)
  #plot(cluster)
  
  #rect.hclust(tree = cluster, k = nclass, border = 2)
  
  
  corte = cutree(tree = cluster, k= nclass)
  plot(x = ds$V1,
       y = ds$V2,
       col = corte,
       xlab = "X",
       ylab = "Y",
       main = paste("Plot del corte con",nclass,"clases",metodo,distan))
  
  
  #segundo método
  
  #cluster = hclust(distancia, method = metodo)
  #dendrogram = as.dendrogram(cluster)
  #plot(dendrogram)
  
  #cortes = cut(dendrogram, h = 26)$upper
  #plot(cortes)
  
  
  # Comparamos datos$class con la salida del método
  #print(table(predecir, corte))
}



distancias <- c("euclidean","maximum","manhattan","binary")


hclust.metodos <- c("ward.D", "single", "complete", "average", "mcquitty",
                    "median", "centroid", "ward.D2")


codo.jambu= function(d){
  mydata <- d
  wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(mydata, centers=i)$withinss)
  plot(1:15,
       wss,
       type="b",
       xlab="Number of Clusters",
       ylab="Within groups sum of squares")
}

# Method "centroid" is typically meant to be used with squared Euclidean distances.


```


- Hacer el k-medias

```{r}

plot(x = a$V1,
     y = a$V2,
     col = a$V3,
     xlim = c(min(a$V1-0.5), max(a$V1+0.5)),
     ylim = c(min(a$V2-0.5), max(a$V2+0.5)),
     xlab = "X",
     ylab = "Y",
     main = "Clustering Rectangular del dataset a")

a.kmedias = kmeans(x = a[, c("V1", "V2")],
                         centers = 3)


plot(x = a$V1,
     y = a$V2,
     col = a.kmedias$cluster)

points(x = a.kmedias$centers[, c("V1", "V2")],
       col = 1:4, pch = 19, cex = 3)

table(a.kmedias$cluster, a$V3)
```



- hclust

```{r,echo=F}
for(i in hclust.metodos){
  for(j in distancias){
    ds.clust(ds = a[,c(1,2)],distan = j, metodo = i,
             nclass = 3, altur = 26, predecir = a$V3)
  }
}
```



- Conclusión de a.csv 

De estas distancias "euclidean","maximum","manhattan","binary" la única que no sirve sin importar el método es binary , todas las demás dan buenos resultados con todos los distintos métodos , excepto el método single que siempre da mal y el metodo median que no da tan mal como el single pero aún así no separa bien los clusters




# guess.csv

```{r,echo=T}
setwd("C:/Users/Alex/Documents/R/DM_T3/AprendizajeNoSupervisado/datos")
guess <- read.csv(file = "guess.csv",header = F)

head(guess)
# no tiene columna con la clase

codo.jambu(guess)


plot(x = guess$V1,
     y = guess$V2,
     xlim = c(min(guess$V1-0.5), max(guess$V1+0.5)),
     ylim = c(min(guess$V2-0.5), max(guess$V2+0.5)),
     xlab = "X",
     ylab = "Y",
     main = "Clustering Rectangular del dataset guess")


# evaluando ambos gráficos , lo mejor es formar 3 clusters

guess.kmedias = kmeans(x = guess,
                   centers = 3)


plot(x = guess$V1,
     y = guess$V2,
     col = guess.kmedias$cluster)

points(x = guess.kmedias$centers[, c("V1", "V2")],
       col = 1:4, pch = 19, cex = 3)
```

## hclust


```{r,echo=F}
for(i in hclust.metodos){
  for(j in distancias){
    if(j != "binary"){
      ds.clust(ds = guess,distan = j, metodo = i,
              nclass = 3, altur = 26, predecir = a$V3)
    }
  }
}
```



## Conclusión:

- Metodos y distancias que funcionan mal para este dataset:
 1.Metodo centroid con cualquier distancia
 2.Metodos median con cualquier distancia: dan 3 clases pero muy mal separadas
 3.Metodo average con distancia distinta a la euclidiana
 4.Distancia binary no está en el informe para evitar que tarde tanto generarlo pero funciona bastante mal
 5.Metodo single funciona bastante mal ,los agrupa todos como un mismo cluster
 
 
 



# Moon.csv


```{r,echo=T}
setwd("C:/Users/Alex/Documents/R/DM_T3/AprendizajeNoSupervisado/datos")
moon <- read.csv(file = "moon.csv",header = F)


#para que tenga color
moon$V3 <- moon$V3 + 1
table(moon$V3)


plot(x = moon$V1,
     y = moon$V2,
     col = moon$V3,
     xlim = c(min(moon$V1-0.5), max(moon$V1+0.5)),
     ylim = c(min(moon$V2-0.5), max(moon$V2+0.5)),
     xlab = "X",
     ylab = "Y",
     main = "Clustering Rectangular del dataset moon")

moon.kmedias = kmeans(x = moon[, c("V1", "V2")],
                   centers = 2)



plot(x = moon$V1,
     y = moon$V2,
     col = moon.kmedias$cluster,
     main = "Plot del k-media del dataset moon")

points(x = moon.kmedias$centers[, c("V1", "V2")],
       col = 1:4, pch = 19, cex = 3)

table(moon.kmedias$cluster, moon$V3)

# En este dataset k-media no funciona bien
```

 
```{r,echo=T}
for(i in hclust.metodos){
  for(j in distancias){
    if (j != "binary"){
        ds.clust(ds = moon[ ,c(1,2)],distan = j, metodo = i,
             nclass = 2, altur = 26)  
    }
  }
}
```
 
 
# Conclusiones

- El único que sirve para este dataset es el método de hclust single con cualquier distancia (excepto binary)




